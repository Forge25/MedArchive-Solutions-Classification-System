{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc2a3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6715c1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data for clustering analysis...\n",
      "Combined dataset for clustering: (2464, 5000)\n",
      "Total documents: 2464\n",
      "Feature dimensions: 5000\n",
      "True labels available for evaluation: 13 classes\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data\n",
    "artifacts_dir = '../artifacts'\n",
    "\n",
    "print(\"Loading preprocessed data for clustering analysis...\")\n",
    "data = joblib.load(os.path.join(artifacts_dir, 'preprocessed_data.joblib'))\n",
    "vectorizer = joblib.load(os.path.join(artifacts_dir, 'tfidf_vectorizer.joblib'))\n",
    "\n",
    "# Extract data components - combine all splits for clustering\n",
    "X_train = data['X_train']\n",
    "X_val = data['X_val']\n",
    "X_test = data['X_test']\n",
    "y_train = data['y_train']\n",
    "y_val = data['y_val']\n",
    "y_test = data['y_test']\n",
    "feature_names = data['feature_names']\n",
    "class_names = data['class_names']\n",
    "\n",
    "# Combine all data for clustering (unsupervised learning)\n",
    "from scipy.sparse import vstack\n",
    "X_all = vstack([X_train, X_val, X_test])\n",
    "y_all = pd.concat([y_train, y_val, y_test], ignore_index=True)\n",
    "\n",
    "print(f\"Combined dataset for clustering: {X_all.shape}\")\n",
    "print(f\"Total documents: {len(y_all)}\")\n",
    "print(f\"Feature dimensions: {X_all.shape[1]}\")\n",
    "print(f\"True labels available for evaluation: {len(class_names)} classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d0e67f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing optimal number of clusters...\n",
      "Computing clustering metrics for different k values...\n",
      "Testing k=2... Silhouette: 0.022\n",
      "Testing k=3... Silhouette: 0.024\n",
      "Testing k=4... Silhouette: 0.027\n",
      "Testing k=5... Silhouette: 0.028\n",
      "Testing k=6... Silhouette: 0.031\n",
      "Testing k=7... Silhouette: 0.034\n",
      "Testing k=8... Silhouette: 0.027\n",
      "Testing k=9... Silhouette: 0.033\n",
      "Testing k=10... Silhouette: 0.036\n",
      "Testing k=11... Silhouette: 0.034\n",
      "Testing k=12... Silhouette: 0.033\n",
      "Testing k=13... Silhouette: 0.039\n",
      "Testing k=14... Silhouette: 0.039\n",
      "Testing k=15... Silhouette: 0.040\n",
      "Testing k=16... Silhouette: 0.041\n",
      "Testing k=17... Silhouette: 0.043\n",
      "Testing k=18... Silhouette: 0.043\n",
      "Testing k=19... Silhouette: 0.045\n",
      "Testing k=20... Silhouette: 0.047\n",
      "\n",
      "Cluster analysis completed!\n"
     ]
    }
   ],
   "source": [
    "# Determine optimal number of clusters using multiple methods\n",
    "print(\"Analyzing optimal number of clusters...\")\n",
    "\n",
    "# Test range of cluster numbers\n",
    "k_range = range(2, 21)  # Test 2 to 20 clusters\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "\n",
    "print(\"Computing clustering metrics for different k values...\")\n",
    "for k in k_range:\n",
    "    print(f\"Testing k={k}...\", end=' ')\n",
    "    \n",
    "    # Fit k-means\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(X_all)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette_avg = silhouette_score(X_all, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    \n",
    "    print(f\"Silhouette: {silhouette_avg:.3f}\")\n",
    "\n",
    "print(\"\\nCluster analysis completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
